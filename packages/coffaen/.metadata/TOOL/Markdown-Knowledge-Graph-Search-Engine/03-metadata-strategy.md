# 03. 메타데이터 전략

## 개요

메타데이터는 이 도구의 핵심 자산이다. 원본 마크다운 저장소에서 사전 추출한 메타데이터를 통해 AI 에이전트는 전체 저장소를 읽지 않고도 관련 문서를 신속하게 찾을 수 있다. 이 문서에서는 세 가지 메타데이터 수준을 비교하고 권장 구현 경로를 제시한다.

## 3단계 메타데이터 전략

### Phase 1: 구조 메타데이터 (Structural Metadata)

순수 파싱만으로 추출 가능한 메타데이터이다. 외부 의존성이 없다.

**포함 내용**:
- 디렉토리 트리 구조 (경로, 깊이, 부모-자식 관계)
- 파일 목록 (경로, mtime, 크기)
- YAML Frontmatter 필드 (태그, Layer 속성, 생성일/수정일, 설명)
- 마크다운 링크 그래프 (from -> to, 앵커 텍스트)
- 기본 그래프 통계 (인/아웃 링크 수, 디렉토리 깊이)
- 헤더 구조 (H1~H6 계층)

**생성 비용**: 낮음. 정규식 + YAML 파서로 완결.

**저장 비용**: 1,000개 문서 기준 약 200~500KB (JSON)

**검색 능력**:
- 디렉토리 기반 범위 탐색: "이 폴더 하위의 모든 문서"
- 링크 기반 관련 문서 탐색: "이 문서가 링크하는/링크받는 문서"
- Frontmatter 필터링: "태그가 X인 문서", "Layer 1 문서"
- 경로 기반 패턴 매칭: "2026년 행동 기록"

**한계**:
- 링크가 없는 문서 간 잠재적 관계 발견 불가
- 의미적 유사도 검색 불가
- 전역적 질문("이 저장소의 핵심 주제는?") 처리 불가

### Phase 2: 의미 메타데이터 (Semantic Metadata)

그래프 알고리즘으로 추출하는 메타데이터이다. LLM 없이 구현 가능하다.

**Phase 1에 추가되는 내용**:
- Wu-Palmer 계층 유사도 (디렉토리 트리 기반 노드 간 거리)
- SCS (Semantic Connectivity Score): 노드 간 경로 수와 길이 종합
- CF (Concept Frequency): Frontmatter 태그/키워드의 저장소 내 빈도
- PageRank: 그래프 전체의 노드별 중요도 점수
- DAG 변환 결과: 제거된 순환 엣지 정보
- 규칙 기반 키워드 추출: 헤더 텍스트, Frontmatter 태그, 반복 출현 명사
- 확산 활성화 사전 파라미터: Layer별 감쇠 인자 기본값

**생성 비용**: 중간. 그래프 알고리즘 실행 필요 (PageRank: 반복 수렴, DAG 변환: O(V+E)).

**저장 비용**: 1,000개 문서 기준 약 1~3MB

**검색 능력** (Phase 1에 추가):
- 확산 활성화 기반 발산적 검색: "이 노드에서 출발하여 관련 있는 문서들"
- 중요도 기반 필터링: "이 폴더에서 가장 중요한 문서"
- 구조적 거리 기반 검색: "이 문서와 계층적으로 가까운 문서"
- 허브 문서 탐지: "다른 문서들이 가장 많이 참조하는 문서"

**한계**:
- 자연어 쿼리에 대한 의미적 매칭 불가 (키워드 매칭만 가능)
- 커뮤니티/클러스터 기반 전역 요약 불가
- 링크도 키워드도 공유하지 않는 문서 간 관계 발견 불가

### Phase 3: 전체 지식 그래프 (Full Knowledge Graph)

LLM과 임베딩 모델에 의존하는 메타데이터이다. 외부 API가 필요하다.

**Phase 2에 추가되는 내용**:
- LLM 기반 트리플 추출: (주체, 서술어, 객체) 정규화된 관계
- LLM 기반 문서 요약: 1~2줄 요약 텍스트
- 엔티티 정규화: 동일 엔티티의 다른 표현을 통합
- 벡터 임베딩: 문서별 의미 벡터 (외부 임베딩 모델 필요)
- Leiden/Louvain 커뮤니티 탐지: 조밀한 하위 그래프 식별
- 커뮤니티별 요약: 커뮤니티 내 문서들의 공통 주제 요약

**생성 비용**: 높음. LLM API 호출 비용 (문서당 수천 토큰), 임베딩 모델 실행 비용.

**저장 비용**: 1,000개 문서 기준 약 10~50MB (벡터 크기 의존)

**검색 능력** (Phase 2에 추가):
- 자연어 쿼리에 대한 의미적 유사도 검색
- 하이브리드 RAG: 벡터 검색(Seed) -> 확산 활성화(그래프 확장)
- 전역적 질문 처리: "이 저장소의 핵심 주제는?"
- 잠재적 관계 발견: 링크 없는 문서 간 의미적 연결

**한계**:
- LLM API 가용성에 의존 (오프라인 동작 불가)
- 트리플 추출의 비결정론성 (같은 문서 재처리 시 다른 결과 가능)
- 임베딩 모델 의존성 (배포/유지 복잡도 증가)
- Claude Code 플러그인 환경에서 네트워크 호출의 보안/신뢰 문제

## 비교 요약

| 항목 | Phase 1 (구조) | Phase 2 (의미) | Phase 3 (전체 KG) |
|------|---------------|---------------|-------------------|
| **외부 의존성** | 없음 | 없음 | LLM API, 임베딩 모델 |
| **생성 비용 (1K docs)** | <5초 | ~30초 | ~5분 (API 대기 포함) |
| **저장 비용** | ~300KB | ~2MB | ~30MB |
| **오프라인 동작** | 가능 | 가능 | 불가 |
| **검색 정밀도** | 기본 | 높음 | 매우 높음 |
| **유지 복잡도** | 낮음 | 중간 | 높음 |
| **AI 토큰 절약** | 중간 | 높음 | 매우 높음 |
| **증분 갱신 비용** | 극히 낮음 | 낮음 (로컬 가중치만) | 높음 (재추출 필요) |

## 권장 구현 경로

```
v0.1 (MVP)  --> Phase 1 전체 + Phase 2 일부 (DAG 변환, 확산 활성화)
v0.2        --> Phase 2 전체 (Wu-Palmer, SCS, PageRank, 규칙 기반 키워드)
v1.0+       --> Phase 3 선택적 (LLM 트리플, 벡터 임베딩, 커뮤니티)
```

**v0.1을 Phase 1 + Phase 2 일부로 설정한 근거**:

대상 저장소가 100줄 이하 원자적 문서라는 특성이 핵심이다.
- 문서 자체가 청크이므로, "관련 문서 전체"를 컨텍스트에 포함하는 전략이 실용적이다
- 확산 활성화는 Phase 2의 핵심 가치이자 연구 보고서의 핵심 기여이다
- Wu-Palmer 유사도와 SCS는 디렉토리 트리와 링크 그래프가 존재하는 순간 계산 가능하다
- PageRank는 그래프 알고리즘만으로 계산 가능하며 허브 문서 탐지에 즉각적 가치를 제공한다

**Phase 3을 선택적으로 분리한 근거**:
- 100줄짜리 문서에 대한 LLM 트리플 추출의 가성비가 불분명하다. 문서 전문을 컨텍스트에 포함하는 것이 트리플 요약보다 정보 손실이 적을 수 있다
- 벡터 임베딩의 한계 효용이 짧은 문서에서는 감소한다 (임베딩의 가치는 긴 문서에서 관련 부분을 찾을 때 극대화됨)
- LLM API 의존성이 오프라인 동작 보장을 깨뜨린다
- Claude Code 플러그인 환경에서 "도구가 다시 LLM을 호출하는" 구조는 비용 이중 발생 + 순환 의존 리스크를 초래한다

## 메타데이터 동기화 전략

### 동기화 리스크

메타데이터가 원본 문서와 불일치하면 검색 품질이 오히려 저하된다.

- **파일 이동/이름 변경**: 경로 기반 노드 ID가 무효화, 모든 인바운드 링크 깨짐
- **링크 무결성**: 삭제된 문서를 참조하는 링크가 메타데이터에 잔존
- **일괄 변경**: git rebase 등으로 수십~수백 파일이 동시 변경

### 완화 전략

1. **쿼리 시점 유효성 검증**: 확산 활성화 결과의 각 노드에 대해 파일 존재 여부를 확인한다. 존재하지 않는 파일은 결과에서 제거하고, 사용자에게 "인덱스가 오래되었을 수 있음"을 표시한다.
2. **인덱스 신선도(Freshness) 표시**: 검색 결과와 함께 "마지막 인덱스 빌드: N분 전" 정보를 반환한다.
3. **Hook 기반 즉시 무효화**: 파일 변경 시 해당 파일의 인덱스 엔트리에 `stale: true` 플래그를 설정한다.
4. **전체 재빌드 권장 임계값**: stale 노드가 전체의 10%를 초과하면 전체 재빌드를 권장한다.

# 05. 핵심 설계 결정

## 개요

연구 보고서의 알고리즘을 실용적 도구로 전환하면서 직면하는 핵심 결정 사항과 트레이드오프를 정리한다. 각 결정에 대해 선택지, 채택안, 근거, 트레이드오프를 명시한다.

## 결정 1: 데이터 모델 입도 -- 페이지 중심 채택

| 선택지 | 설명 |
|--------|------|
| A. 페이지 중심 | 마크다운 파일 전체를 하나의 노드로 취급 |
| B. 블록 중심 | 문단, 리스트 아이템, 헤더 단위로 노드를 분할 |

**채택: A (페이지 중심)**

**근거**: 대상 저장소의 문서가 100줄 이하 원자적 문서이므로, 블록 단위 분할은 과잉이다. "문서 = 청크" 등식이 성립하며, 그래프 복잡도(노드 수)를 최소화한다.

**트레이드오프**: 100줄을 초과하는 문서가 포함된 범용 저장소에서는 검색 정밀도가 하락한다. 이 한계는 VaultProfile 설정으로 블록 중심 모드를 향후 추가하여 대응할 수 있다.

## 결정 2: 그래프 저장 -- 인메모리 + JSON 직렬화

| 선택지 | 설명 |
|--------|------|
| A. 인메모리 + JSON | Node.js Map/Set + JSON 파일 |
| B. SQLite | 경량 관계형 DB |
| C. 외부 그래프 DB | Neo4j 등 |

**채택: A (인메모리 + JSON)**

**근거**:
- 외부 의존성 제로 (Claude Code 플러그인 배포 단순화)
- 수백~수천 문서 규모에서 충분한 성능
- 인간이 직접 JSON을 열어 디버깅 가능
- `.maencof/` 삭제 후 재빌드로 완전 복구 가능

**트레이드오프**: 수만 문서 이상에서 JSON 파싱 지연과 메모리 압박이 발생한다. 1만 문서를 임계점으로 설정하고, 초과 시 SQLite 또는 바이너리 직렬화로의 마이그레이션 경로를 열어둔다.

## 결정 3: 순환 처리 -- smartAE 휴리스틱

| 선택지 | 설명 |
|--------|------|
| A. 단순 제거 | DFS 역방향 엣지를 무조건 제거 |
| B. smartAE | 제거 후 재삽입 가능한 엣지를 복원하여 정보 손실 최소화 |
| C. 순환 허용 | DAG 변환 없이 순환을 허용하고 방문 제한으로 대응 |

**채택: B (smartAE)**

**근거**: 마크다운 저장소의 상호 참조(A->B, B->A)는 자연스러운 패턴이다. 단순 제거(A)는 유의미한 양방향 관계를 파괴한다. 순환 허용(C)은 확산 활성화에서 에너지 무한 증폭 리스크를 초래한다. smartAE는 O(m log m) 복잡도로 최소 정보 손실을 달성한다.

**트레이드오프**: 최적해(최소 FAS)를 보장하지 않는 휴리스틱이지만, 실용적 문서 규모에서 근사치와 최적해의 차이는 무시 가능하다.

## 결정 4: 검색 모델 -- 확산 활성화 우선

| 선택지 | 설명 |
|--------|------|
| A. 확산 활성화 (SA) | 인지 심리학 기반, 쿼리 의존적, 동적 |
| B. 재시작 랜덤 워크 (RWR) | 마르코프 연쇄, 글로벌 중요도 |
| C. 하이브리드 (SA + 벡터) | 벡터 검색으로 시드 후 SA 확산 |

**채택: A (확산 활성화) -- Phase 2까지. C (하이브리드)는 Phase 3에서 선택적 도입.**

**근거**: SA 모델은 "현재 맥락에서 출발한 발산적 탐색"이라는 도구의 핵심 가치와 직결된다. RWR은 쿼리 독립적인 정적 분포를 계산하므로, 맥락 종속적 검색에 부적합하다. SA의 동적 가중치 조정 유연성이 4-Layer 지식 모델과 결합될 때 최대 가치를 발휘한다.

**트레이드오프**: SA 파라미터 튜닝(발화 임계값, 감쇠 인자, 최대 홉)이 검색 품질을 크게 좌우한다. 합리적 기본값을 제공하되, Layer별 차등 감쇠 인자를 적용하여 자동 최적화한다.

**Layer별 감쇠 인자 설계 방향**:
- Layer 1 (핵심 자아): 낮은 감쇠 -- 멀리까지 확산하여 광범위한 영향력 반영
- Layer 4 (행동 기억): 높은 감쇠 -- 가까운 이웃만 활성화하여 시간적 근접성 반영

## 결정 5: LLM 의존성 경계 -- Phase 2까지 LLM-free

| 선택지 | 설명 |
|--------|------|
| A. 전면 LLM 활용 | 모든 의미 추출에 LLM 사용 |
| B. LLM-free 우선 | Phase 2까지 LLM 없이, Phase 3에서 선택적 도입 |
| C. 완전 LLM-free | LLM 사용 영구 배제 |

**채택: B (LLM-free 우선)**

**근거**:
- Claude Code 플러그인에서 "도구가 LLM을 호출"하면 비용 이중 발생 + 순환 의존 리스크
- LLM API 가용성에 의존하면 인덱스 빌드의 신뢰성이 하락
- 오프라인 동작 보장이 플러그인의 핵심 가치
- 100줄 원자적 문서에서 LLM 트리플 추출의 가성비가 불분명

**트레이드오프**: 자연어 수준의 의미 추론이 불가하고, 링크도 키워드도 공유하지 않는 문서 간 잠재적 관계를 발견할 수 없다. Phase 3에서 LLM opt-in 기능을 제공하여 필요 시 확장한다.

## 결정 6: 대상 저장소 최적화 -- 특수 구조 우선, 범용 확장 가능

| 선택지 | 설명 |
|--------|------|
| A. 범용 MD 저장소 | Obsidian, Logseq, 일반 위키 모두 지원 |
| B. 4-Layer 특수 최적화 | 연구 제안서의 특수 구조에 최적화 |

**채택: B (특수 구조 우선) + A로 확장 가능한 인터페이스**

**근거**: 연구 제안서가 정의한 4-Layer 모델과 100줄 제약은 도메인 특화 최적화 기회를 제공한다. 예를 들어 Layer 속성을 확산 활성화의 감쇠 인자에 반영하거나, 100줄 제한을 전제로 "문서 = 청크" 등식을 적용하여 청킹 로직을 대폭 단순화할 수 있다.

**확장 경로**: 핵심 알고리즘(그래프 구축, SA, DAG 변환)은 범용적으로 설계하고, 특수 최적화는 VaultProfile 설정으로 분리한다.

## 알고리즘 우선순위 큐

연구 보고서의 알고리즘을 **구현 난이도 / 외부 의존성 / 사용자 가치** 3축으로 평가한다.

| 알고리즘 | 구현 난이도 | 외부 의존성 | 사용자 가치 | **우선순위** | Phase |
|---------|-----------|-----------|-----------|------------|-------|
| 디렉토리 트리 파싱 | 낮음 | 없음 | 높음 | **P0** | 1 |
| 링크 그래프 구축 | 낮음 | 없음 | 높음 | **P0** | 1 |
| Frontmatter 파싱 | 낮음 | 없음 | 높음 | **P0** | 1 |
| 증분 변경 감지 | 낮음 | 없음 | 높음 | **P0** | 1 |
| DFS 순환 탐지 + DAG 변환 | 중간 | 없음 | 중간 | **P0** | 1 |
| 확산 활성화 엔진 | 중간 | 없음 | 높음 | **P0** | 1 |
| Wu-Palmer 계층 유사도 | 낮음 | 없음 | 중간 | **P1** | 2 |
| SCS (연결 강도) | 중간 | 없음 | 중간 | **P1** | 2 |
| PageRank | 중간 | 없음 | 중간 | **P1** | 2 |
| 규칙 기반 키워드 추출 | 낮음 | 없음 | 중간 | **P1** | 2 |
| Leiden 커뮤니티 탐지 | 높음 | 가능 | 중간 | **P2** | 2+ |
| 벡터 임베딩 통합 | 높음 | 필수 | 높음 | **P2** | 3 |
| LLM 트리플 추출 | 매우 높음 | 필수 | 중간 | **P3** | 3 |
| LLM 문서 요약 | 높음 | 필수 | 중간 | **P3** | 3 |

**원칙**: P0 -> P1 -> P2 -> P3 순서로 구현한다. 각 우선순위 단계의 완료가 다음 단계의 전제 조건이다. P0만으로 릴리즈 가능한 MVP가 되어야 한다.

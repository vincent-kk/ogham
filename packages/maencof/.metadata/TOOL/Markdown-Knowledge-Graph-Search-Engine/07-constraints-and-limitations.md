# 07. 한계와 제약

## 기술적 한계

### 규모 한계

인메모리 그래프 + JSON 직렬화 구조이므로 문서 수에 따른 성능 한계가 존재한다.

| 규모 | 예상 성능 | 비고 |
|------|----------|------|
| ~1,000 문서 | 원활 | 인덱스 빌드 <5초, 쿼리 <50ms |
| ~5,000 문서 | 양호 | 인덱스 빌드 <30초, 쿼리 <100ms |
| ~10,000 문서 | 임계점 | JSON 파싱 지연 체감, 메모리 수백 MB |
| 10,000+ 문서 | 한계 초과 | SQLite 또는 바이너리 직렬화로 마이그레이션 필요 |

**완화**: 대부분의 개인 지식 저장소는 수천 문서 이하이다. 1만 문서 이상의 규모가 필요한 경우 별도 마이그레이션 경로를 제공한다.

### 언어/형식 한계

- **마크다운 전용**: `.md` 파일만 내용 분석 대상. 비마크다운 파일(이미지, PDF, 코드)은 "존재하지만 내용 미분석" 노드로만 표현
- **링크 형식**: 표준 마크다운 상대 경로 링크 `[text](./path.md)`를 기본 지원. 위키링크 `[[wikilink]]` 형식은 설정에 따라 선택적 지원 (구현 결정 미확정)
- **Frontmatter**: YAML Frontmatter를 기대하나, 없는 문서도 처리 가능 (메타데이터 부족으로 검색 정밀도 하락)
- **문자 인코딩**: UTF-8 전용

### 의미론적 한계 (Phase 2까지)

- **자연어 이해 불가**: LLM 없이는 "비슷한 의미"를 판단할 수 없다. 검색은 키워드 매칭 + 그래프 구조에 의존
- **동의어/유의어 인식 불가**: "happy"와 "joyful"을 같은 개념으로 인식하지 못한다
- **새로운 관계 추론 불가**: 명시적 링크와 디렉토리 구조에 없는 관계는 발견할 수 없다

### 실시간성 한계

- **전역 메트릭 지연**: PageRank, 커뮤니티 탐지는 전체 빌드 시에만 갱신. 증분 갱신에서는 이전 값 유지
- **대규모 구조 변경**: 폴더 이동, 대량 파일 이름 변경 시 전체 재인덱싱 필요 (증분 갱신으로 불충분)
- **인덱스 신선도**: 빌드 이후 변경된 문서에 대해서는 stale 표시만 가능, 자동 재인덱싱 아님

## 운영적 제약

### Claude Code 플러그인 환경

- **Hook 타임아웃**: 3~5초 제한으로 인해 Hook에서 복잡한 그래프 연산 불가
- **번들 크기**: 네이티브 바인딩이 포함된 의존성 추가 시 배포 복잡도 증가
- **네트워크 접근**: 플러그인에서 외부 API(LLM, 임베딩) 호출의 보안/신뢰 이슈

### 검색 결과의 불확실성

- **확산 활성화는 확률적 근사**: SA 기반 검색 결과는 파라미터(발화 임계값, 감쇠 인자)에 따라 크게 달라질 수 있다. "정답"이 보장되지 않는다.
- **파라미터 민감도**: 감쇠 인자를 0.1만 변경해도 결과 상위 10개가 완전히 바뀔 수 있다
- **결과 재현성**: 동일 쿼리 + 동일 인덱스에서는 결정적(deterministic) 결과를 보장하나, 인덱스 갱신 후에는 결과가 달라진다

## 이 도구가 하지 않아야 하는 것

1. **원본 마크다운 수정**: 읽기 전용 도구이다. 자동 태그 추가, 링크 삽입 등은 별도 도구로 분리
2. **LLM API 키 관리**: 환경 변수 또는 Claude Code 인증 메커니즘에 위임
3. **비마크다운 파일 내용 분석**: PDF, 이미지 등의 내용 추출은 범위 밖
4. **인덱스를 진실의 원천으로 사용**: 인덱스는 파생물이다. `.maencof/` 삭제 후 재빌드로 복구 가능해야 한다
5. **과도한 컨텍스트 주입**: Hook에서의 자동 주입은 토큰 예산(기본 2000 토큰)을 엄격히 제한

## Pre-mortem: 실패 시나리오

### 실패 시나리오 1: "완전한 구현"을 시도하다 출시 불가

**서술**: 연구 보고서의 8개 알고리즘을 모두 구현하려 하다가, LLM 트리플 추출과 벡터 임베딩 단계에서 외부 의존성/비용 문제에 막혀 전체 파이프라인이 완성되지 못한다. 아무것도 동작하지 않는 반제품이 된다.

**완화 전략**: Phase 구분을 엄격히 준수한다. P0 알고리즘(디렉토리 트리, 링크 그래프, DAG, 확산 활성화)만으로 릴리즈 가능한 MVP를 먼저 완성한다. 각 Phase는 이전 Phase만으로 독립적 가치를 제공해야 한다.

### 실패 시나리오 2: 메타데이터 동기화 실패로 신뢰 상실

**서술**: 사용자가 저장소를 활발히 편집하는 동안 인덱스가 실시간 갱신되지 않아, 삭제된 문서나 이동된 문서가 검색 결과에 포함된다. 한두 번의 "거짓 결과"를 경험한 사용자가 도구 전체를 불신한다.

**완화 전략**:
- 쿼리 시점에 파일 존재 여부를 검증하여 존재하지 않는 결과를 필터링
- "마지막 인덱스 빌드: N분 전" 신선도 정보를 항상 결과와 함께 반환
- stale 노드 비율이 10%를 초과하면 "인덱스 갱신을 권장합니다" 경고 표시

### 실패 시나리오 3: AI/인간 이중 인터페이스로 자원 분산

**서술**: AI 에이전트용 토큰 최적화와 인간용 네비게이션 인터페이스를 동시에 개발하다가, 양쪽 모두 중도 완성 상태가 된다.

**완화 전략**:
- Primary persona를 AI 에이전트로 확정하고, 모든 API/출력을 토큰 효율성 우선으로 설계
- 인간용 인터페이스는 Skill의 포맷팅 레이어로만 한정 (마크다운 테이블 출력)
- 핵심 알고리즘(core/)과 출력 포맷(search/)을 명확히 분리하여, 새로운 출력 형태 추가 시 core/ 변경 불필요

## 향후 확장 가능성

현재 설계에서 의도적으로 배제하되, 인터페이스 수준에서 확장 가능성을 열어두는 항목:

| 항목 | 현재 상태 | 확장 시점 |
|------|----------|----------|
| 벡터 임베딩 통합 | 인터페이스만 정의 | Phase 3, 사용자 요구 시 |
| LLM 기반 트리플/요약 | opt-in 옵션으로 예약 | Phase 3, 가성비 검증 후 |
| 위키링크 `[[]]` 지원 | 설정 플래그로 예약 | 사용자 요구 시 |
| SQLite 저장소 | 마이그레이션 경로 설계 | 1만+ 문서 규모 |
| 실시간 인덱스 갱신 | Watch 모드 예약 | 사용 패턴 분석 후 |
| 전용 에이전트 | Layer 3 슬롯 예약 | 자율적 지식 탐색 수요 시 |
